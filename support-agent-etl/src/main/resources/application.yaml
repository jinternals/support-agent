spring:
    main:
      web-application-type: none
    ai:
      ollama:
        base-url: http://localhost:11434
        init:
          pull-model-strategy: when_missing
          timeout: 10m
          max-retries: 2
        embedding:
          model: mxbai-embed-large:latest
        chat:
          model: Mradul/gemma3-tools:27b
          options:
            temperature: 0.6
      vectorstore:
        qdrant:
          host: localhost
          port: 6334
          collection-name: support
          use-tls: false
          initialize-schema: true

logging.level.org.springframework.ai: DEBUG
logging.level.io.modelcontextprotocol: DEBUG
